---
layout: post-python
title: Feature Extraction with Bag of Words (BOWs)
category: machine-learning-python
---
In order to model a text documents, the raw text cannot be fed directly to the algorithm as these algorithms expect numerical feature vectors so instead we need to turn the text content into numerical feature vectors.

<span class='w3-text-blue'> From the [scikit-learn documentation](https://scikit-learn.org/stable/modules/feature_extraction.html):</span>
<b>
We call vectorization the general process of turning a collection of text documents into numerical feature vectors.
</b>

When modelling a data it is important to decide what features of the input are relevant, and how to encode those features. When we consider a textual data such as a sentence or a document  for instance the observable features are the counts and the order of the letters and the words within the text and as such we a way to extract these features from the text. There are several ways of extracting features from a textual data but in this tutorial we will only consider a very common feature extraction procedures for sentences and documents known as the <b> bag-of-words approach (BOW)</b> which looks at the histogram of the unique words within the text ( considering each word count as a feature.) 


<p><b>Bag Of Words (BOWs) Approach</b></p> 
Is a feature extraction technique used for extracting features from textual data and is commonly used in problems such as language modeling and document classification.  A bag-of-words is a representation of textual data, describing the occurrence of words within a sentence or document, disregarding grammar and the order of words.

<p><b>How does Bag of Words Works</b></p>
In order to understand how bag of words works let consider the two simple text documents:

```
1. Boys like playing football and Emma is a boy so Emma likes playing football

2  Mary likes watching movies 

```

Based on these two text documents, a list of token (words) for each document is as follows

```javascript
['Boys', 'like', 'playing', 'football', 'and', 'Emma', 'is' 'a', 'boy', 'so', 'Emma', 

'likes', 'playing', 'football']


['Mary', 'likes', 'watching', 'movies']


```
denoting document 1 by doc1 and 2  by doc2, we will construct a dictionary (key->value pair) of
words for both doc1 and doc2 where each key is a word, and each value is the number of occurrences of that word in the given text document.


```javascript
doc1={ 'a' : 1, 'and' : 1, 'boy' : 1, 'Boys' : 1, 'Emma' : 2, 'football' : 2, 

'is' : 1, 'like' : 1,  'likes' : 1, 'playing' : 2,   'so' : 1}

dco2={'likes' : 1, 'Mary' : 1,  'movies' : 1 ,'watching' : 1}
```

<b>NOTE :</b> the order of the words is not important


considering **a** as a stop word, we first define our vocabulary words, which is the set of all unique words found in our document set and it consist of
```javascript
and, boy, boys, emma,  football, is, like, likes, mary, movies, playing, so, watching

```
and the  features extracted using bag of words for the document set will be


<img class=" w3-border" src="{{'/assets/images/python/bog.jpg' |relative_url}}">


<p><b>scikit-learn CountVectorize implementation</b></p>
<p>
Using CountVectorize the text is preprocessed, tokenize and stopwords are filtered, it then builds a dictionary of features and transforms documents to feature vectors:</p>

```python
from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd
```

```
docs=['Boys like playing football and Emma is a boy so Emma likes playing football',
   "Mary likes watching movies"]
```
```python
feature_extr=CountVectorizer()
model=feature_extr.fit_transform(docs)
```


<img class=" w3-border" src="{{'/assets/images/python/bog1.jpg' |relative_url}}">


<p> <b>References:</b></p>
<hr>
- <a href='https://en.wikipedia.org/wiki/Bag-of-words_model' target="_blank">Bag-of-words model - Wikipedia
</a><br>
- <a href="https://www.amazon.com/Language-Processing-Synthesis-Lectures-Technologies/dp/1627052984/ref=as_li_ss_tl?ie=UTF8&qid=1502062931&sr=8-1&keywords=Neural+Network+Methods+in+Natural+Language+Processing&linkCode=sl1&tag=inspiredalgor-20&linkId=d63df073fea3ebe2d405820570b3ff03" target="_blank">Yoav Goldberg (2017). Neural Network Methods in Natural Language Processing</a><br>


- <a href="https://scikit-learn.org/stable/modules/feature_extraction.html" target="_blank">Feature extraction-scikit-learn documentation</a><br>

